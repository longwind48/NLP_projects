{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ST446 Distributed Computing for Big Data\n",
    "## Homework - Traci Lim Zheng Wen\n",
    "### Milan Vojnovic and Christine Yuen, LT 2018\n",
    "---\n",
    "\n",
    "## P2: Spark streaming\n",
    "\n",
    "In this homework assignment problem your task is to track the sample mean and unbiased sample variance of the number of words per tweet using Spark streaming API. You should calculate the mean and variance for all the tweets that you receive over time, not just for the last received batch of the stream. This means that you need to calculate the mean and the variance recursively using the Spark streaming concept of a \"stateful\" operation.\n",
    "\n",
    "You should calculate two different versions of sample mean and variance estimators with different step sizes:\n",
    "\n",
    "**Decaying step size**: Recursive evaluations of mean and unbiased sample variance for an input stream of observations $x_1, x_2, \\ldots$ with decaying step size:\n",
    "\n",
    "* Mean: $m_{n+1} = (1-w_n) m_n + w_n x_{n+1}$ where $w_n = 1/(n+1)$\n",
    "* Sample variance: $\\sigma^2_{n+1} = a_n \\sigma^2_n + b_n (x_{n+1}-m_n)^2$ where $a_n$ and $b_n$ are two sequences whose values you need to work out as a warm-up exercise\n",
    "\n",
    "**Fixed step size**: Recursive evaluation with fixed step size (exponentially weighted smoothing):\n",
    "\n",
    "* Mean: same as above but with $w_n = 0.2$ for all $n$\n",
    "* Sample variance: same as above with $a_n = 1 - b_n$ and $b_n = 0.2$ for all $n$\n",
    "\n",
    "## How to get Twitter data\n",
    "\n",
    "Please see the exercise from one of our class sessions for guidance on how to receive a live Twitter data stream: https://github.com/lse-st446/lectures/blob/master/week06/class/TwitterStreamingAPI.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark Context\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.1.1 pyspark-shell'\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "import json\n",
    "\n",
    "ssc = StreamingContext(sc, 10)\n",
    "kafka_stream = KafkaUtils.createStream(ssc, \\\n",
    "                                       \"localhost:2181\", \\\n",
    "                                       \"test-consumer-group\", \\\n",
    "                                        {\"twitter-stream\":1})\n",
    "ssc.checkpoint(\"checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Print the first tweet of each batch\n",
    "def returnText(x):\n",
    "    try:\n",
    "        return x['text']\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "lines = kafka_stream.map(lambda x: json.loads(x[1])).map(returnText)\n",
    "lines.pprint(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.count().pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#from nltk.corpus import stopwords\n",
    "import string\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def get_tokens(line):\n",
    "    tokens = word_tokenize(line)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation from each word\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # NOT filter out stop words\n",
    "    #words = [w for w in words if not w in stop_words]\n",
    "    return len(words)\n",
    "\n",
    "counts = lines.map(lambda row: (1, get_tokens(row))) # number of words per tweet\n",
    "#counts.pprint(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: decaying step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateMetricsDecay(new_values, prev_decay):\n",
    "    # if old_metric do not exist, set them to 0\n",
    "    if not prev_decay:\n",
    "        prev_decay = [0,0,0]\n",
    "    count_decay = prev_decay[0] # retrieve prior total count\n",
    "    mean_decay = prev_decay[1] # retrieve prior mean\n",
    "    var_decay = prev_decay[2] # retrieve prior variance\n",
    "    for i in new_values:\n",
    "        count_decay += 1 # n+1\n",
    "        w_n = 1/count_decay # 1/(n+1)\n",
    "        if count_decay >= 2:\n",
    "            b_n = 1/(count_decay-1) # equivalent to 1/(n+1-1) = 1/n\n",
    "        elif count_decay == 1:\n",
    "            b_n = 0 # to avoid 1/0\n",
    "        prev_mean_decay = mean_decay\n",
    "        mean_decay = (1-w_n)*prev_mean_decay + i*w_n # M_n+1 = (1-W_n)M_n + W_n*x_n+1\n",
    "        var_decay = (1-b_n)*var_decay + b_n*(i-prev_mean_decay)**2 # var_n+1 = (1-b_n)*var_n + b_n*(x_n+1 - M_n)^2\n",
    "    return [count_decay, mean_decay, var_decay]\n",
    "\n",
    "running_metrics = counts.updateStateByKey(updateMetricsDecay)\n",
    "# Print count_decay, mean_decay, var_decay\n",
    "running_metrics.pprint(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:08:40\n",
      "-------------------------------------------\n",
      "RT @mitchellvii: I think Trump's takeaway message from this Omnibus will be this:\n",
      "\n",
      "\"If I wanted funding for our military I had to accept th…\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:08:40\n",
      "-------------------------------------------\n",
      "9225\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:08:40\n",
      "-------------------------------------------\n",
      "(1, [9225, 18.00747967479676, 30.86996021140999])\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:08:50\n",
      "-------------------------------------------\n",
      "RT @EricHolder: Constitution does not require citizenship question. This is purely political. Trump Administration is trying to rig the 202…\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:08:50\n",
      "-------------------------------------------\n",
      "1712\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:08:50\n",
      "-------------------------------------------\n",
      "(1, [10937, 18.08018652281251, 29.998630396215905])\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:09:00\n",
      "-------------------------------------------\n",
      "RT @susankeith: Join us at #Rutgers for @jeremyscahill and @ShaunKing in Reporting on Racial Conflict at Home and Wars Abroad in the Age of…\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:09:00\n",
      "-------------------------------------------\n",
      "214\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:09:00\n",
      "-------------------------------------------\n",
      "(1, [11151, 18.091023226616475, 29.915825489957637])\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:09:10\n",
      "-------------------------------------------\n",
      "RT @4everNeverTrump: Farmers were some of the strongest supporters of Donald Trump in 2016.\n",
      "\n",
      "WTF did they think he was going to do?!?! http…\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:09:10\n",
      "-------------------------------------------\n",
      "237\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:09:10\n",
      "-------------------------------------------\n",
      "(1, [11388, 18.093958552862674, 29.823556900588194])\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:09:20\n",
      "-------------------------------------------\n",
      "@free2meetu @IvankaTrump Yes, and trump was banging porn stars while his “gift from heaven “ was breast feeding\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:09:20\n",
      "-------------------------------------------\n",
      "235\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:09:20\n",
      "-------------------------------------------\n",
      "(1, [11623, 18.096962918351505, 29.722217097155323])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: fixed step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_n = 0.2 # fixed step size for each instance iteration\n",
    "\n",
    "def updateMetricsFixed(new_values, old_metric_fix):\n",
    "    # if old_metric do not exist, set them to 0\n",
    "    if not old_metric_fix:\n",
    "        old_metric_fix = [0,0]\n",
    "    mean_fix = old_metric_fix[0] # retrieve prior mean\n",
    "    var_fix = old_metric_fix[1] # retrieve prior variance\n",
    "    for i in new_values:\n",
    "        mean_fix = (1-w_n)*mean_fix + w_n*i # update mean with fixed step size\n",
    "        var_fix = (1-w_n)*var_fix + w_n*(i-mean_fix)**2 # update variance with fixed step-size\n",
    "    return [mean_fix, var_fix]\n",
    "\n",
    "running_metrics = counts.updateStateByKey(updateMetricsFixed)\n",
    "# Print mean_fixed, var_fixed\n",
    "running_metrics.pprint(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:09:50\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:09:50\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:09:50\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:10:00\n",
      "-------------------------------------------\n",
      "RT @mitchellvii: I think Trump's takeaway message from this Omnibus will be this:\n",
      "\n",
      "\"If I wanted funding for our military I had to accept th…\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:10:00\n",
      "-------------------------------------------\n",
      "12496\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:10:00\n",
      "-------------------------------------------\n",
      "(1, [18.022925032345793, 14.103199518654023])\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:10:10\n",
      "-------------------------------------------\n",
      "@BBCWorld Latinos will be given three choices to identify themselves.\n",
      "1 Latino-not best and brightest\n",
      "2 Latino-Rapi… https://t.co/z4DcGnkok7\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:10:10\n",
      "-------------------------------------------\n",
      "228\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:10:10\n",
      "-------------------------------------------\n",
      "(1, [16.228988803837776, 26.45662407493698])\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:10:20\n",
      "-------------------------------------------\n",
      "RT @CREWcrew: Your daily reminder that Trump is the first president elected since Nixon to refuse to release his tax returns, and any payme…\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:10:20\n",
      "-------------------------------------------\n",
      "198\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:10:20\n",
      "-------------------------------------------\n",
      "(1, [17.06464953236602, 21.31184471897676])\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:10:30\n",
      "-------------------------------------------\n",
      "RT @JoanneTirado09: \"Working class people voted for TRUMP\".\n",
      "ROSEANNE BARR ENDORSED TRUMP!\n",
      "LISTEN TO ROSEANNE \n",
      "TRUMP 2020\n",
      "@therealroseanne…\n",
      "...\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:10:30\n",
      "-------------------------------------------\n",
      "217\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-03-27 14:10:30\n",
      "-------------------------------------------\n",
      "(1, [15.112072057605223, 42.1134618144361])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
