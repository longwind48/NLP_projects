{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ST446 Distributed Computing for Big Data\n",
    "## Homework\n",
    "### Milan Vojnovic and Christine Yuen, LT 2018\n",
    "---\n",
    "\n",
    "## P3: Topic Modelling\n",
    "\n",
    "In this homework assignment problem, you are asked to perform a semantic analysis of the DBLP author publications dataset `dblp/author_large.txt`. \n",
    "\n",
    "A. Use Latent Dirichlet Allocation (LDA) to cluster publications by using words in their titles and represent each publication by 10 topics. You should:\n",
    "\n",
    "A.1. Convert titles to tokens by:\n",
    "   * Tokenizing words in the title of each publication\n",
    "   * Removing stop words using the nltk package\n",
    "   * Removing puctuations, numbers or other symbols\n",
    "   * Lemmatizing tokens\n",
    "\n",
    "Note you may skip or add some additional editing of the tokens, but if you do this provide a justification for it. \n",
    "\n",
    "A.2. Convert tokens into sparse vectors\n",
    "\n",
    "A.3. Use the LDA algorithm to find out 10 topics for each publication and represent each topic with first few most relevant words. Note that you can choose to use different number of topics rather than 10, again if you do so provide a justification.\n",
    "\n",
    "A.4. Comment the obtained results\n",
    "\n",
    "B. Address each question as in part A, but with each \"document\" representing publication tiles of specific author. For example, if an author Y wrote \"introduction to databases\" and \"database design\", then the \"document\" for the author Y will be \"introduction to database database design\". \n",
    "\n",
    "In addition, calculate the topic density vector for each author and use the topic density to calculate the cosine simularity for each pair of authors. For example, if the topic density for author X is [0.2,0.8, 0,...] and topic density vector for author Y is [0.1, 0.9, 0, ...], then the cosine simularity is $\\frac{0.2*0.1+0.8*0.9}{\\sqrt{0.2^2+0.8^2}\\sqrt{0.1^2+0.9^2}}$. Show the 10 most similar author pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName('QuestionP3') \\\n",
    ".set(\"spark.kryoserializer.buffer.max\", \"128m\") \\\n",
    ".set(\"spark.kryoserializer.buffer\", \"64m\") \\\n",
    ".set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ardd0 = sc.textFile(\"C:/hduser/author-large.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"On Modeling Conformance for Flexible Transformation over Data Models. On Modeling Conformance for Flexible Transformation over Data Models. Knowledge Representation and Transformation in Ontology-based Data Integration. Knowledge Representation and Transformation in Ontology-based Data Integration. The 'Family of Languages' Approach to Semantic Interoperability. The 'Family of Languages' Approach to Semantic Interoperability. UML for the Semantic Web: Transformation-Based Approaches. UML for the Semantic Web: Transformation-Based Approaches. UML for the Semantic Web: Transformation-Based Approaches. Tracing Data Lineage Using Schema Transformation Pathways. Tracing Data Lineage Using Schema Transformation Pathways. Transforming UML Domain Descriptions into Configuration Knowledge Bases. Transforming UML Domain Descriptions into Configuration Knowledge Bases. Transforming UML Domain Descriptions into Configuration Knowledge Bases. Transforming UML Domain Descriptions into Configuration Knowledge Bases. Transforming UML Domain Descriptions into Configuration Knowledge Bases. Transforming Data Models with UML. Transforming Data Models with UML. Schema Conversion Methods between XML and Relational Models. Schema Conversion Methods between XML and Relational Models. Schema Conversion Methods between XML and Relational Models. RDFT: A Mapping Meta-Ontology for Web Service Integration. A Logic Programming Approach to RDF Document and Query Transformation. Ontology Extraction for Distributed Environments. Ontology Extraction for Distributed Environments. Ontology Extraction for Distributed Environments. Ontology Extraction for Distributed Environments.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ardd1 = ardd0.map(lambda x: x.split(\"\\t\", 3)) \\\n",
    "        .map(lambda x: (x[1],x[2])) \\\n",
    "        .reduceByKey(lambda x,y: x + \" \" + y) \\\n",
    "        .map(lambda x: (x[1]))\n",
    "ardd1.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.1. Convert titles to tokens\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "stop_words = set(stopwords.words('english'))\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "def get_tokens(line):\n",
    "    tokens = word_tokenize(line)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuations from each word\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if len(w) > 3]\n",
    "    # stemming the words\n",
    "    words = [lmtzr.lemmatize(w) for w in words]\n",
    "    return (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ardd2 = ardd1.map(lambda line: (1, get_tokens(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  ['modeling',\n",
       "   'conformance',\n",
       "   'flexible',\n",
       "   'transformation',\n",
       "   'data',\n",
       "   'model',\n",
       "   'modeling',\n",
       "   'conformance',\n",
       "   'flexible',\n",
       "   'transformation',\n",
       "   'data',\n",
       "   'model',\n",
       "   'knowledge',\n",
       "   'representation',\n",
       "   'transformation',\n",
       "   'ontologybased',\n",
       "   'data',\n",
       "   'integration',\n",
       "   'knowledge',\n",
       "   'representation',\n",
       "   'transformation',\n",
       "   'ontologybased',\n",
       "   'data',\n",
       "   'integration',\n",
       "   'family',\n",
       "   'language',\n",
       "   'approach',\n",
       "   'semantic',\n",
       "   'interoperability',\n",
       "   'family',\n",
       "   'language',\n",
       "   'approach',\n",
       "   'semantic',\n",
       "   'interoperability',\n",
       "   'semantic',\n",
       "   'transformationbased',\n",
       "   'approach',\n",
       "   'semantic',\n",
       "   'transformationbased',\n",
       "   'approach',\n",
       "   'semantic',\n",
       "   'transformationbased',\n",
       "   'approach',\n",
       "   'tracing',\n",
       "   'data',\n",
       "   'lineage',\n",
       "   'using',\n",
       "   'schema',\n",
       "   'transformation',\n",
       "   'pathway',\n",
       "   'tracing',\n",
       "   'data',\n",
       "   'lineage',\n",
       "   'using',\n",
       "   'schema',\n",
       "   'transformation',\n",
       "   'pathway',\n",
       "   'transforming',\n",
       "   'domain',\n",
       "   'description',\n",
       "   'configuration',\n",
       "   'knowledge',\n",
       "   'base',\n",
       "   'transforming',\n",
       "   'domain',\n",
       "   'description',\n",
       "   'configuration',\n",
       "   'knowledge',\n",
       "   'base',\n",
       "   'transforming',\n",
       "   'domain',\n",
       "   'description',\n",
       "   'configuration',\n",
       "   'knowledge',\n",
       "   'base',\n",
       "   'transforming',\n",
       "   'domain',\n",
       "   'description',\n",
       "   'configuration',\n",
       "   'knowledge',\n",
       "   'base',\n",
       "   'transforming',\n",
       "   'domain',\n",
       "   'description',\n",
       "   'configuration',\n",
       "   'knowledge',\n",
       "   'base',\n",
       "   'transforming',\n",
       "   'data',\n",
       "   'model',\n",
       "   'transforming',\n",
       "   'data',\n",
       "   'model',\n",
       "   'schema',\n",
       "   'conversion',\n",
       "   'method',\n",
       "   'relational',\n",
       "   'model',\n",
       "   'schema',\n",
       "   'conversion',\n",
       "   'method',\n",
       "   'relational',\n",
       "   'model',\n",
       "   'schema',\n",
       "   'conversion',\n",
       "   'method',\n",
       "   'relational',\n",
       "   'model',\n",
       "   'rdft',\n",
       "   'mapping',\n",
       "   'metaontology',\n",
       "   'service',\n",
       "   'integration',\n",
       "   'logic',\n",
       "   'programming',\n",
       "   'approach',\n",
       "   'document',\n",
       "   'query',\n",
       "   'transformation',\n",
       "   'ontology',\n",
       "   'extraction',\n",
       "   'distributed',\n",
       "   'environment',\n",
       "   'ontology',\n",
       "   'extraction',\n",
       "   'distributed',\n",
       "   'environment',\n",
       "   'ontology',\n",
       "   'extraction',\n",
       "   'distributed',\n",
       "   'environment',\n",
       "   'ontology',\n",
       "   'extraction',\n",
       "   'distributed',\n",
       "   'environment']),\n",
       " (1,\n",
       "  ['logical',\n",
       "   'handling',\n",
       "   'inconsistent',\n",
       "   'default',\n",
       "   'information',\n",
       "   'logical',\n",
       "   'handling',\n",
       "   'inconsistent',\n",
       "   'default',\n",
       "   'information',\n",
       "   'logical',\n",
       "   'handling',\n",
       "   'inconsistent',\n",
       "   'default',\n",
       "   'information',\n",
       "   'logical',\n",
       "   'handling',\n",
       "   'inconsistent',\n",
       "   'default',\n",
       "   'information',\n",
       "   'approximate',\n",
       "   'reasoning',\n",
       "   'system',\n",
       "   'handling',\n",
       "   'uncertainty',\n",
       "   'imprecision',\n",
       "   'information',\n",
       "   'system',\n",
       "   'introduction',\n",
       "   'fuzzy',\n",
       "   'possibility',\n",
       "   'theorybased',\n",
       "   'treatment',\n",
       "   'flexible',\n",
       "   'query',\n",
       "   'uncertain',\n",
       "   'imprecise',\n",
       "   'database',\n",
       "   'introduction',\n",
       "   'fuzzy',\n",
       "   'possibility',\n",
       "   'theorybased',\n",
       "   'treatment',\n",
       "   'flexible',\n",
       "   'query',\n",
       "   'uncertain',\n",
       "   'imprecise',\n",
       "   'database',\n",
       "   'uncertainty',\n",
       "   'intelligent',\n",
       "   'database',\n",
       "   'bibliography',\n",
       "   'uncertainty',\n",
       "   'management',\n",
       "   'information',\n",
       "   'system',\n",
       "   'probabilistic',\n",
       "   'bayesian',\n",
       "   'representation',\n",
       "   'uncertainty',\n",
       "   'information',\n",
       "   'system',\n",
       "   'pragmatic',\n",
       "   'introduction',\n",
       "   'probabilistic',\n",
       "   'bayesian',\n",
       "   'representation',\n",
       "   'uncertainty',\n",
       "   'information',\n",
       "   'system',\n",
       "   'pragmatic',\n",
       "   'introduction',\n",
       "   'probabilistic',\n",
       "   'bayesian',\n",
       "   'representation',\n",
       "   'uncertainty',\n",
       "   'information',\n",
       "   'system',\n",
       "   'pragmatic',\n",
       "   'introduction',\n",
       "   'uncertain',\n",
       "   'incomplete',\n",
       "   'inconsistent',\n",
       "   'data',\n",
       "   'scientific',\n",
       "   'statistical',\n",
       "   'database',\n",
       "   'uncertain',\n",
       "   'incomplete',\n",
       "   'inconsistent',\n",
       "   'data',\n",
       "   'scientific',\n",
       "   'statistical',\n",
       "   'database',\n",
       "   'uncertain',\n",
       "   'incomplete',\n",
       "   'inconsistent',\n",
       "   'data',\n",
       "   'scientific',\n",
       "   'statistical',\n",
       "   'database',\n",
       "   'classification',\n",
       "   'uncertainty',\n",
       "   'technique',\n",
       "   'relation',\n",
       "   'application',\n",
       "   'need',\n",
       "   'introduction',\n",
       "   'source',\n",
       "   'uncertainty',\n",
       "   'imprecision',\n",
       "   'inconsistency',\n",
       "   'information',\n",
       "   'system',\n",
       "   'knowledge',\n",
       "   'discovery',\n",
       "   'acquisition',\n",
       "   'imperfect',\n",
       "   'information',\n",
       "   'imperfect',\n",
       "   'information',\n",
       "   'imprecision',\n",
       "   'uncertainty',\n",
       "   'transferable',\n",
       "   'belief',\n",
       "   'model',\n",
       "   'belief',\n",
       "   'representation',\n",
       "   'transferable',\n",
       "   'belief',\n",
       "   'model',\n",
       "   'belief',\n",
       "   'representation',\n",
       "   'uncertainty',\n",
       "   'information',\n",
       "   'retrieval',\n",
       "   'system',\n",
       "   'uncertainty',\n",
       "   'information',\n",
       "   'retrieval',\n",
       "   'system',\n",
       "   'imperfect',\n",
       "   'information',\n",
       "   'relational',\n",
       "   'database',\n",
       "   'imperfect',\n",
       "   'information',\n",
       "   'relational',\n",
       "   'database']),\n",
       " (1,\n",
       "  ['actor',\n",
       "   'conceptual',\n",
       "   'foundation',\n",
       "   'concurrent',\n",
       "   'objectoriented',\n",
       "   'programming',\n",
       "   'actor',\n",
       "   'conceptual',\n",
       "   'foundation',\n",
       "   'concurrent',\n",
       "   'objectoriented',\n",
       "   'programming',\n",
       "   'groundwork',\n",
       "   'object',\n",
       "   'database',\n",
       "   'model',\n",
       "   'definition',\n",
       "   'group',\n",
       "   'making',\n",
       "   'source',\n",
       "   'firstclass',\n",
       "   'object',\n",
       "   'definition',\n",
       "   'group',\n",
       "   'making',\n",
       "   'source',\n",
       "   'firstclass',\n",
       "   'object',\n",
       "   'definition',\n",
       "   'group',\n",
       "   'making',\n",
       "   'source',\n",
       "   'firstclass',\n",
       "   'object',\n",
       "   'objectoriented',\n",
       "   'specification',\n",
       "   'unifying',\n",
       "   'functional',\n",
       "   'objectoriented',\n",
       "   'relational',\n",
       "   'programming',\n",
       "   'logical',\n",
       "   'semantics',\n",
       "   'unifying',\n",
       "   'functional',\n",
       "   'objectoriented',\n",
       "   'relational',\n",
       "   'programming',\n",
       "   'logical',\n",
       "   'semantics',\n",
       "   'model',\n",
       "   'objectbased',\n",
       "   'inheritance',\n",
       "   'model',\n",
       "   'objectbased',\n",
       "   'inheritance',\n",
       "   'vulcan',\n",
       "   'logical',\n",
       "   'concurrent',\n",
       "   'object',\n",
       "   'vulcan',\n",
       "   'logical',\n",
       "   'concurrent',\n",
       "   'object',\n",
       "   'vulcan',\n",
       "   'logical',\n",
       "   'concurrent',\n",
       "   'object',\n",
       "   'vulcan',\n",
       "   'logical',\n",
       "   'concurrent',\n",
       "   'object',\n",
       "   'beta',\n",
       "   'programming',\n",
       "   'language',\n",
       "   'beta',\n",
       "   'programming',\n",
       "   'language',\n",
       "   'beta',\n",
       "   'programming',\n",
       "   'language',\n",
       "   'beta',\n",
       "   'programming',\n",
       "   'language',\n",
       "   'blockstructure',\n",
       "   'objectoriented',\n",
       "   'language',\n",
       "   'development',\n",
       "   'implementation',\n",
       "   'objectoriented',\n",
       "   'dbms',\n",
       "   'development',\n",
       "   'implementation',\n",
       "   'objectoriented',\n",
       "   'dbms',\n",
       "   'mechanism',\n",
       "   'specifying',\n",
       "   'structure',\n",
       "   'large',\n",
       "   'layered',\n",
       "   'system',\n",
       "   'objectoriented',\n",
       "   'framework',\n",
       "   'conceptual',\n",
       "   'programming',\n",
       "   'type',\n",
       "   'evolution',\n",
       "   'objectoriented',\n",
       "   'database',\n",
       "   'type',\n",
       "   'evolution',\n",
       "   'objectoriented',\n",
       "   'database',\n",
       "   'substrate',\n",
       "   'objectoriented',\n",
       "   'interface',\n",
       "   'design',\n",
       "   'substrate',\n",
       "   'objectoriented',\n",
       "   'interface',\n",
       "   'design',\n",
       "   'substrate',\n",
       "   'objectoriented',\n",
       "   'interface',\n",
       "   'design',\n",
       "   'inheritance',\n",
       "   'development',\n",
       "   'encapsulated',\n",
       "   'software',\n",
       "   'system',\n",
       "   'objectoriented',\n",
       "   'classification',\n",
       "   'paradigm'])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ardd2.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conformance',\n",
       " 'flexible',\n",
       " 'transformation',\n",
       " 'conformance',\n",
       " 'flexible',\n",
       " 'transformation',\n",
       " 'transformation',\n",
       " 'ontologybased',\n",
       " 'transformation',\n",
       " 'ontologybased']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_stop_words = ardd2.flatMap(lambda r: r[1]).map(lambda r: (r,1)).reduceByKey(lambda a,b: a+b)\n",
    "\n",
    "doc_stop_words = doc_stop_words.filter(lambda a: a[1]>15000).map(lambda r: r[0]).collect()\n",
    "\n",
    "ardd3 = ardd2.map(lambda r: (r[0],[w for w in r[1] if not w in doc_stop_words]))    \n",
    "\n",
    "ardd3.take(1)[0][1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dummy=1, words=['conformance', 'flexible', 'transformation', 'conformance', 'flexible', 'transformation', 'transformation', 'ontologybased', 'transformation', 'ontologybased', 'family', 'interoperability', 'family', 'interoperability', 'transformationbased', 'transformationbased', 'transformationbased', 'tracing', 'lineage', 'schema', 'transformation', 'pathway', 'tracing', 'lineage', 'schema', 'transformation', 'pathway', 'transforming', 'domain', 'description', 'configuration', 'base', 'transforming', 'domain', 'description', 'configuration', 'base', 'transforming', 'domain', 'description', 'configuration', 'base', 'transforming', 'domain', 'description', 'configuration', 'base', 'transforming', 'domain', 'description', 'configuration', 'base', 'transforming', 'transforming', 'schema', 'conversion', 'relational', 'schema', 'conversion', 'relational', 'schema', 'conversion', 'relational', 'rdft', 'mapping', 'metaontology', 'transformation', 'ontology', 'ontology', 'ontology', 'ontology'])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A.2. Convert tokens into sparse vectors\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "ardd4 = spark.createDataFrame(ardd3, [\"dummy\",\"words\"])\n",
    "ardd4.cache()\n",
    "ardd4.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|dummy|               words|            features|\n",
      "+-----+--------------------+--------------------+\n",
      "|    1|[conformance, fle...|(61425,[13,20,69,...|\n",
      "|    1|[logical, handlin...|(61425,[48,56,57,...|\n",
      "|    1|[actor, conceptua...|(61425,[3,6,56,64...|\n",
      "|    1|[entity, realtion...|(61425,[6,10,41,2...|\n",
      "|    1|[expert, effectiv...|(61425,[138,188,1...|\n",
      "|    1|[manufacturing, m...|(61425,[4,11,14,2...|\n",
      "|    1|[abduction, analo...|(61425,[21,39,45,...|\n",
      "|    1|[computinganstze,...|(61425,[24,35,46,...|\n",
      "|    1|[firstclass, data...|(61425,[9,17,59,6...|\n",
      "|    1|[dataflow, educat...|(61425,[6,15,17,5...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"features\", minDF=2)\n",
    "\n",
    "cv_model = cv.fit(ardd4)\n",
    "\n",
    "ardd4_w_features = cv_model.transform(ardd4)\n",
    "ardd4_w_features.cache()\n",
    "ardd4_w_features.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseVector(64293, {14: 2.0, 56: 2.0, 263: 3.0, 372: 2.0, 635: 2.0, 999: 1.0, 1288: 7.0, 1322: 2.0, 4927: 3.0, 5603: 2.0, 23719: 1.0})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "#from pyspark.ml import linalg as ml_linalg\n",
    "def as_mllib_vector(v):\n",
    "    return Vectors.sparse(v.size, v.indices, v.values)\n",
    "\n",
    "features = ardd4_w_features.select(\"features\")\n",
    "feature_vec = features.rdd.map(lambda r: as_mllib_vector(r[0]))\n",
    "\n",
    "feature_vec.cache()\n",
    "feature_vec.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary from CountVectorizerModel is:\n",
      "['calibration', 'belief', 'phone', 'discovering', 'gaussian', 'relevance', 'tolerance', 'awareness', 'difference', 'browsing', 'mac', 'dynamically', 'satellite', 'need', 'family', 'connection', 'movement', 'cycle', 'dialogue', 'implication', 'behaviour', 'care', 'ofdm', 'providing', 'bus', 'plan', 'modified', 'theorem', 'template', 'dna', 'arithmetic', 'life', 'alternative', 'density', 'parallelism', 'im', 'networking', 'tolerant', 'part', 'receiver', 'microprocessor', 'forecasting', 'free', 'qualitative', 'bounded', 'detector', 'gate', 'interconnection', 'controlled', 'mathematical', 'step', 'bit', 'direction', 'ct', 'minimal', 'wide', 'ontologybased', 'workload', 'frequent', 'fingerprint', 'customer', 'concurrency', 'compensation', 'selective', 'automation', 'disk', 'pose', 'creation', 'call', 'deterministic', 'potential', 'string', 'categorization', 'formation', 'repository', 'ant', 'lower', 'embedding', 'mr', 'center', 'consideration', 'effectiveness', 'timed', 'migration', 'endtoend', 'tuning', 'auction', 'lattice', 'output', 'compact', 'regular', 'organizational', 'converter', 'interconnect', 'dimensional', 'reactive', 'ring', 'light', 'portal', 'trace']\n"
     ]
    }
   ],
   "source": [
    "print (\"Vocabulary from CountVectorizerModel is:\")\n",
    "print(cv_model.vocabulary[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.3. Use the LDA algorithm to find out 10 topics for each publication \n",
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "lda = LDA(k=10, maxIter=20)\n",
    "lda_model = lda.fit(ardd4_w_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+----------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|topic|termIndices                                               |termWeights                                                                                                                                                                                                                         |\n",
      "+-----+----------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0    |[51, 13, 54, 6, 25, 35, 29, 17, 48, 66]                   |[0.0031124212570762, 0.0029970895184058765, 0.002814869481181054, 0.0028039405692821947, 0.0027185610680734765, 0.002718345167029759, 0.002544572717819843, 0.0024897966853867216, 0.0024278665110751573, 0.002416755989643203]     |\n",
      "|1    |[61, 176, 65, 15, 629, 131, 51, 18, 118, 100]             |[0.0022681465794034445, 0.0018118256505639304, 0.001416488396370735, 0.0010830602326756113, 9.903536719801831E-4, 8.740926421040364E-4, 6.826575203354101E-4, 6.196758910393286E-4, 5.957731261125634E-4, 5.923316017485198E-4]     |\n",
      "|2    |[34, 22, 76, 70, 1, 9, 33, 128, 96, 40]                   |[0.005998093569070857, 0.0046524113416589845, 0.004624686616606985, 0.004531058950313043, 0.0042080827768542295, 0.003995801638272968, 0.0038608035140841063, 0.003682836394124249, 0.0036761258687505695, 0.0035010673204974763]   |\n",
      "|3    |[80, 242, 36, 147, 77, 548, 297, 93, 52, 136]             |[0.010589375045996286, 0.00863861228438607, 0.007978322349098569, 0.007623929432428789, 0.006176983495992332, 0.005249362938701211, 0.005230519727662914, 0.00512544783974206, 0.004653313390002923, 0.004222248025931596]          |\n",
      "|4    |[65, 448, 89, 67, 79, 155, 22, 231, 630, 18]              |[0.0022346715431207738, 0.0019595610184789084, 0.0016532983971807229, 0.0015506764227812715, 0.0015075835397734742, 0.0014521468179171419, 0.001395285863964428, 0.0013724534974253048, 0.0013484486356544448, 0.001336382517813648]|\n",
      "|5    |[2295, 915, 13, 65, 6586, 75, 390, 5481, 54, 21]          |[0.002874828383582966, 0.0014556046118721264, 0.0013466152325163172, 0.0010481263403671532, 0.001014827458259904, 0.0010069248628805502, 9.848967041470888E-4, 9.673933338932559E-4, 9.129939577341307E-4, 8.654895893145344E-4]    |\n",
      "|6    |[18, 67, 172, 185, 30, 156, 3, 107, 148, 448]             |[0.006701139136649088, 0.004921626852763602, 0.004508305367334927, 0.004314076942092567, 0.004075477007321345, 0.004045250212461897, 0.004020558187420035, 0.004009628614597965, 0.003917017033483129, 0.003649721242091446]        |\n",
      "|7    |[846, 1625, 1559, 808, 166, 3233, 4705, 3056, 4696, 3018] |[0.014798957065755923, 0.007741210148132817, 0.0070341465442124084, 0.004614239886434845, 0.004076927503739791, 0.0037137254235007256, 0.0030562528719537013, 0.0029775376586260146, 0.002822593296479902, 0.0025529057783993015]   |\n",
      "|8    |[80, 77, 2044, 1038, 629, 2, 286, 45, 242, 8]             |[0.0029085182931876848, 0.0021387194899482086, 0.0020468756763821, 0.0016667377180459963, 0.0016501061651341916, 0.0013341636869408787, 0.001173120792519983, 0.0011467886151683721, 0.0011424541569887944, 0.0010809664426829622]  |\n",
      "|9    |[1237, 994, 944, 1094, 1811, 1363, 2148, 3031, 1953, 2159]|[0.006171310744948131, 0.005720028855416764, 0.005457968067298944, 0.0049485968156372465, 0.0031369929738065275, 0.0030206853890175217, 0.002823868853308556, 0.002757939662212869, 0.0025018822054426355, 0.0024636710761271694]   |\n",
      "+-----+----------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "['multiagent' 'ontology' 'business' 'specification' 'experience' 'project'\n",
      " 'game' 'theory' 'reasoning' 'objectoriented']\n",
      "['complexity' 'automaton' 'evolutionary' 'computation' 'topic' 'set'\n",
      " 'multiagent' 'traffic' 'property' 'class']\n",
      "['face' 'vector' 'shape' 'surface' 'sequence' 'matching' 'coding' 'color'\n",
      " 'reconstruction' 'identification']\n",
      "['reconfigurable' 'fpga' 'synthesis' 'cmos' 'hardware' 'fpgas' 'vlsi'\n",
      " 'delay' 'methodology' 'array']\n",
      "['evolutionary' 'mimo' 'cooperative' 'allocation' 'evolution' 'rate'\n",
      " 'vector' 'cognitive' 'interference' 'traffic']\n",
      "['clef' 'identity' 'ontology' 'evolutionary' 'geoclef' 'social'\n",
      " 'architectural' 'imageclef' 'business' 'effect']\n",
      "['traffic' 'allocation' 'multicast' 'packet' 'heterogeneous'\n",
      " 'transmission' 'mechanism' 'optical' 'peertopeer' 'mimo']\n",
      "['pour' 'donne' 'dans' 'prolog' 'base' 'connaissances' 'logique'\n",
      " 'approche' 'programmation' 'systme']\n",
      "['reconfigurable' 'hardware' 'cot' 'note' 'topic' 'component' 'trust'\n",
      " 'cluster' 'fpga' 'task']\n",
      "['para' 'eine' 'eines' 'einer' 'entwicklung' 'durch' 'einsatz'\n",
      " 'informatik' 'beispiel' 'einem']\n"
     ]
    }
   ],
   "source": [
    "# Describe topics\n",
    "topics = lda_model.describeTopics(10)\n",
    "\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "\n",
    "topics.show(truncate=False)\n",
    "\n",
    "# Shows the results\n",
    "#transformed = lda_model.transform(news_df_w_features)\n",
    "#transformed.columns\n",
    "import numpy as np\n",
    "topic_i = topics.select(\"termIndices\").rdd.map(lambda r: r[0]).collect()\n",
    "for i in topic_i:\n",
    "    print(np.array(cv_model.vocabulary)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower bound on the log likelihood of the entire corpus: -72849486.59277481\n",
      "The upper bound on the perplexity: 8.378121104596655\n"
     ]
    }
   ],
   "source": [
    "ll = lda_model.logLikelihood(ardd4_w_features)\n",
    "lp = lda_model.logPerplexity(ardd4_w_features)\n",
    "\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on the perplexity: \" + str(lp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A4. Comment on results:\n",
    "\n",
    "Other than the typical tokenizing processes, I only allowed words that are more than 3 characters because rogue topics like 'en' and 'um' appear when trained with the LDA model. I limited the words frequency threshold at 15000 times to improve the quality and relevancy of topics.\n",
    "\n",
    "I train the model on the corpus with 10 topics, and set the maximum number of iterations to 20.\n",
    "\n",
    "Restricting words that occurs less than a certain threshold certainly helped improve the model, because some publications were poorly represented by a handful of irrelevant topics like 'apl' and non-english words like 'prolog' and 'ingres'. I used the perplexity upper bound and results from LDA model as metrics to tune the threshold, keeping the number of iterations at 20. Although I felt that allowing 10 topics to represent each publication is too much of a stretch, LDA does a relatively good job with an upper on perplexity score of 8.38."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Object SQL - A Language for the Design and Implementation of Object Databases. Overview of the Iris DBMS. Overview of the Iris DBMS. A Physician's Workstation as an Application of Object-Oriented Database Technology in Healthcare. A Powerful Wide-Area Information Clent. Database Programming Languages: A Functional Approach. Integrating a Structured-Text Retrieval System with an Object-Oriented Database System.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brdd1 = ardd0.map(lambda x: x.split(\"\\t\", 3)) \\\n",
    "            .map(lambda x: (x[0],x[2])) \\\n",
    "            .reduceByKey(lambda x,y: x+ \" \" +y) \\\n",
    "            .map(lambda x: x[1])\n",
    "brdd1.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B.1. Convert titles to tokens\n",
    "brdd2 = brdd1.map(lambda line: (1, get_tokens(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  ['object',\n",
       "   'language',\n",
       "   'design',\n",
       "   'implementation',\n",
       "   'object',\n",
       "   'database',\n",
       "   'overview',\n",
       "   'iris',\n",
       "   'dbms',\n",
       "   'overview',\n",
       "   'iris',\n",
       "   'dbms',\n",
       "   'physician',\n",
       "   'workstation',\n",
       "   'application',\n",
       "   'objectoriented',\n",
       "   'database',\n",
       "   'technology',\n",
       "   'healthcare',\n",
       "   'powerful',\n",
       "   'widearea',\n",
       "   'information',\n",
       "   'clent',\n",
       "   'database',\n",
       "   'programming',\n",
       "   'language',\n",
       "   'functional',\n",
       "   'approach',\n",
       "   'integrating',\n",
       "   'structuredtext',\n",
       "   'retrieval',\n",
       "   'system',\n",
       "   'objectoriented',\n",
       "   'database',\n",
       "   'system']),\n",
       " (1,\n",
       "  ['physical',\n",
       "   'object',\n",
       "   'management',\n",
       "   'service',\n",
       "   'query',\n",
       "   'optimization',\n",
       "   'object',\n",
       "   'base',\n",
       "   'exploiting',\n",
       "   'relational',\n",
       "   'technique',\n",
       "   'application',\n",
       "   'generator',\n",
       "   'idea',\n",
       "   'programming',\n",
       "   'language',\n",
       "   'extension',\n",
       "   'service',\n",
       "   'field',\n",
       "   'approach',\n",
       "   'resource',\n",
       "   'constrained',\n",
       "   'sensoractor',\n",
       "   'network',\n",
       "   'autoglobe',\n",
       "   'automatische',\n",
       "   'administration',\n",
       "   'dienstbasierten',\n",
       "   'datenbankanwendungen',\n",
       "   'strongly',\n",
       "   'typed',\n",
       "   'persistent',\n",
       "   'object',\n",
       "   'model',\n",
       "   'polymorphism',\n",
       "   'konzepte',\n",
       "   'integration',\n",
       "   'abstrakter',\n",
       "   'datentypen',\n",
       "   'verteilte',\n",
       "   'metadatenverwaltung',\n",
       "   'anfragebearbeitung',\n",
       "   'internetdatenquellen',\n",
       "   'kontextbasierte',\n",
       "   'personalisierung',\n",
       "   'service',\n",
       "   'sicherheit',\n",
       "   'einem',\n",
       "   'javabasierten',\n",
       "   'verteilten',\n",
       "   'system',\n",
       "   'autonomer',\n",
       "   'objekte',\n",
       "   'flexible',\n",
       "   'autorisierung',\n",
       "   'servicefderationen',\n",
       "   'xmlarchivierung',\n",
       "   'betriebswirtschaftlicher',\n",
       "   'datenbankobjekte',\n",
       "   'anforderungen',\n",
       "   'datenbanksysteme',\n",
       "   'multitenancy',\n",
       "   'softwareasaserviceapplikationen',\n",
       "   'data',\n",
       "   'staging',\n",
       "   'olap',\n",
       "   'oltpapplications',\n",
       "   'rfid',\n",
       "   'data',\n",
       "   'efficient',\n",
       "   'access',\n",
       "   'control',\n",
       "   'composite',\n",
       "   'application',\n",
       "   'hisbase',\n",
       "   'informationsfusion',\n",
       "   'netzwerken',\n",
       "   'dynamic',\n",
       "   'load',\n",
       "   'balancing',\n",
       "   'virtualized',\n",
       "   'database',\n",
       "   'service',\n",
       "   'using',\n",
       "   'hint',\n",
       "   'load',\n",
       "   'forecasting',\n",
       "   'matching',\n",
       "   'evaluation',\n",
       "   'disjunctive',\n",
       "   'predicate',\n",
       "   'data',\n",
       "   'stream',\n",
       "   'sharing',\n",
       "   'edaplex',\n",
       "   'objectoriented',\n",
       "   'extension',\n",
       "   'daplex',\n",
       "   'engineering',\n",
       "   'application',\n",
       "   'data',\n",
       "   'base',\n",
       "   'system',\n",
       "   'modelling',\n",
       "   'data',\n",
       "   'distributed',\n",
       "   'query',\n",
       "   'query',\n",
       "   'optimization',\n",
       "   'schemabased',\n",
       "   'processing',\n",
       "   'optimization',\n",
       "   'complex',\n",
       "   'query',\n",
       "   'schemabased',\n",
       "   'consolidating',\n",
       "   'access',\n",
       "   'control',\n",
       "   'composite',\n",
       "   'application',\n",
       "   'workflow',\n",
       "   'correcting',\n",
       "   'anomaly',\n",
       "   'standard',\n",
       "   'inheritance',\n",
       "   'constraintbased',\n",
       "   'approach',\n",
       "   'framework',\n",
       "   'strong',\n",
       "   'typing',\n",
       "   'type',\n",
       "   'inference',\n",
       "   'persistent',\n",
       "   'object',\n",
       "   'model',\n",
       "   'integrated',\n",
       "   'approach',\n",
       "   'resource',\n",
       "   'pool',\n",
       "   'management',\n",
       "   'policy',\n",
       "   'efficiency',\n",
       "   'quality',\n",
       "   'metric',\n",
       "   'gridbased',\n",
       "   'data',\n",
       "   'stream',\n",
       "   'processing',\n",
       "   'escience',\n",
       "   'community',\n",
       "   'training',\n",
       "   'partitioning',\n",
       "   'scheme',\n",
       "   'good',\n",
       "   'shape',\n",
       "   'federated',\n",
       "   'data',\n",
       "   'grid',\n",
       "   'multithreaded',\n",
       "   'architecture',\n",
       "   'prefetching',\n",
       "   'object',\n",
       "   'base',\n",
       "   'framework',\n",
       "   'contextaware',\n",
       "   'adaptable',\n",
       "   'service',\n",
       "   'building',\n",
       "   'dynamic',\n",
       "   'market',\n",
       "   'place',\n",
       "   'using',\n",
       "   'hyperqueries',\n",
       "   'workloadaware',\n",
       "   'data',\n",
       "   'partitioning',\n",
       "   'communitydriven',\n",
       "   'data',\n",
       "   'grid',\n",
       "   'managing',\n",
       "   'longrunning',\n",
       "   'query',\n",
       "   'data',\n",
       "   'stream',\n",
       "   'sharing',\n",
       "   'autonomy',\n",
       "   'ubiquity',\n",
       "   'coping',\n",
       "   'complexity',\n",
       "   'distributed',\n",
       "   'world',\n",
       "   'optimized',\n",
       "   'workflow',\n",
       "   'authorization',\n",
       "   'service',\n",
       "   'oriented',\n",
       "   'architecture',\n",
       "   'introduction',\n",
       "   'optimizing',\n",
       "   'join',\n",
       "   'expression',\n",
       "   'extended',\n",
       "   'abstract',\n",
       "   'partitionbased',\n",
       "   'clustering',\n",
       "   'object',\n",
       "   'base',\n",
       "   'theory',\n",
       "   'practice',\n",
       "   'einsatz',\n",
       "   'dataspaces',\n",
       "   'inkrementelle',\n",
       "   'informationsintegration',\n",
       "   'medizin',\n",
       "   'optimierung',\n",
       "   'boolescher',\n",
       "   'ausdrcke',\n",
       "   'objektbanken',\n",
       "   'collaborative',\n",
       "   'query',\n",
       "   'coordination',\n",
       "   'communitydriven',\n",
       "   'data',\n",
       "   'grid',\n",
       "   'future',\n",
       "   'database',\n",
       "   'technology',\n",
       "   'driving',\n",
       "   'force',\n",
       "   'direction',\n",
       "   'efficient',\n",
       "   'bulk',\n",
       "   'deletes',\n",
       "   'relational',\n",
       "   'database',\n",
       "   'publish',\n",
       "   'subscribe',\n",
       "   'architecture',\n",
       "   'distributed',\n",
       "   'metadata',\n",
       "   'management',\n",
       "   'adaptable',\n",
       "   'pointer',\n",
       "   'swizzling',\n",
       "   'strategy',\n",
       "   'object',\n",
       "   'base',\n",
       "   'autoglobe',\n",
       "   'automatic',\n",
       "   'administration',\n",
       "   'concept',\n",
       "   'serviceoriented',\n",
       "   'database',\n",
       "   'application',\n",
       "   'integrating',\n",
       "   'semijoinreducers',\n",
       "   'state',\n",
       "   'query',\n",
       "   'processor',\n",
       "   'dynamic',\n",
       "   'extensible',\n",
       "   'query',\n",
       "   'processing',\n",
       "   'superpeer',\n",
       "   'based',\n",
       "   'system',\n",
       "   'benchmarking',\n",
       "   'archiving',\n",
       "   'scenario',\n",
       "   'wsamuse',\n",
       "   'service',\n",
       "   'architecture',\n",
       "   'multimedia',\n",
       "   'service',\n",
       "   'quality',\n",
       "   'service',\n",
       "   'enabled',\n",
       "   'database',\n",
       "   'application',\n",
       "   'semantic',\n",
       "   'caching',\n",
       "   'service',\n",
       "   'reliable',\n",
       "   'adaptable',\n",
       "   'security',\n",
       "   'engineering',\n",
       "   'databaseweb',\n",
       "   'service',\n",
       "   'capacity',\n",
       "   'management',\n",
       "   'demand',\n",
       "   'prediction',\n",
       "   'next',\n",
       "   'generation',\n",
       "   'data',\n",
       "   'center',\n",
       "   'transaction',\n",
       "   'control',\n",
       "   'mechanism',\n",
       "   'object',\n",
       "   'cache',\n",
       "   'interface',\n",
       "   'autonomous',\n",
       "   'object',\n",
       "   'natural',\n",
       "   'model',\n",
       "   'complex',\n",
       "   'application',\n",
       "   'uniform',\n",
       "   'concept',\n",
       "   'storing',\n",
       "   'manipulating',\n",
       "   'engineering',\n",
       "   'object',\n",
       "   'prefetch',\n",
       "   'support',\n",
       "   'relation',\n",
       "   'object',\n",
       "   'base',\n",
       "   'authorization',\n",
       "   'framework',\n",
       "   'sharing',\n",
       "   'data',\n",
       "   'service',\n",
       "   'federation',\n",
       "   'database',\n",
       "   'patchwork',\n",
       "   'internet',\n",
       "   'database',\n",
       "   'performance',\n",
       "   'real',\n",
       "   'world',\n",
       "   'tpcd',\n",
       "   'experience',\n",
       "   'paper',\n",
       "   'function',\n",
       "   'materialization',\n",
       "   'object',\n",
       "   'base',\n",
       "   'database',\n",
       "   'application',\n",
       "   'system',\n",
       "   'tutorial',\n",
       "   'objectoriented',\n",
       "   'database',\n",
       "   'system',\n",
       "   'engineering',\n",
       "   'application',\n",
       "   'access',\n",
       "   'support',\n",
       "   'object',\n",
       "   'base',\n",
       "   'optimizing',\n",
       "   'disjunctive',\n",
       "   'query',\n",
       "   'expensive',\n",
       "   'predicate',\n",
       "   'multitenant',\n",
       "   'database',\n",
       "   'software',\n",
       "   'service',\n",
       "   'schemamapping',\n",
       "   'technique',\n",
       "   'comparison',\n",
       "   'flexible',\n",
       "   'schema',\n",
       "   'software',\n",
       "   'service',\n",
       "   'generating',\n",
       "   'tailored',\n",
       "   'middleware',\n",
       "   'wireless',\n",
       "   'sensor',\n",
       "   'network',\n",
       "   'application',\n",
       "   'security',\n",
       "   'distributed',\n",
       "   'eservice',\n",
       "   'composition',\n",
       "   'objectglobe',\n",
       "   'ubiquitous',\n",
       "   'query',\n",
       "   'processing',\n",
       "   'internet',\n",
       "   'reliable',\n",
       "   'service',\n",
       "   'execution',\n",
       "   'deployment',\n",
       "   'dynamic',\n",
       "   'environment',\n",
       "   'evaluating',\n",
       "   'functional',\n",
       "   'join',\n",
       "   'along',\n",
       "   'nested',\n",
       "   'reference',\n",
       "   'set',\n",
       "   'objectrelational',\n",
       "   'objectoriented',\n",
       "   'database',\n",
       "   'optimizing',\n",
       "   'query',\n",
       "   'universal',\n",
       "   'quantification',\n",
       "   'objectoriented',\n",
       "   'objectrelational',\n",
       "   'database',\n",
       "   'finding',\n",
       "   'data',\n",
       "   'neighborhood',\n",
       "   'serviceglobe',\n",
       "   'distributing',\n",
       "   'eservices',\n",
       "   'across',\n",
       "   'internet',\n",
       "   'dualbuffering',\n",
       "   'strategy',\n",
       "   'object',\n",
       "   'base',\n",
       "   'generalised',\n",
       "   'hash',\n",
       "   'team',\n",
       "   'join',\n",
       "   'groupby',\n",
       "   'advanced',\n",
       "   'query',\n",
       "   'processing',\n",
       "   'object',\n",
       "   'base',\n",
       "   'using',\n",
       "   'access',\n",
       "   'support',\n",
       "   'relation',\n",
       "   'blackboard',\n",
       "   'architecture',\n",
       "   'query',\n",
       "   'optimization',\n",
       "   'object',\n",
       "   'base',\n",
       "   'optimizing',\n",
       "   'boolean',\n",
       "   'expression',\n",
       "   'objectbases',\n",
       "   'streamglobe',\n",
       "   'processing',\n",
       "   'sharing',\n",
       "   'data',\n",
       "   'stream',\n",
       "   'gridbased',\n",
       "   'infrastructure',\n",
       "   'design',\n",
       "   'implementation',\n",
       "   'extensible',\n",
       "   'database',\n",
       "   'management',\n",
       "   'system',\n",
       "   'supporting',\n",
       "   'user',\n",
       "   'defined',\n",
       "   'data',\n",
       "   'type',\n",
       "   'function',\n",
       "   'bypassing',\n",
       "   'join',\n",
       "   'disjunctive',\n",
       "   'query',\n",
       "   'hyperqueries',\n",
       "   'dynamic',\n",
       "   'distributed',\n",
       "   'query',\n",
       "   'processing',\n",
       "   'internet',\n",
       "   'experience',\n",
       "   'report',\n",
       "   'exploiting',\n",
       "   'advanced',\n",
       "   'database',\n",
       "   'optimization',\n",
       "   'feature',\n",
       "   'largescale',\n",
       "   'installation',\n",
       "   'dynamic',\n",
       "   'workload',\n",
       "   'management',\n",
       "   'large',\n",
       "   'data',\n",
       "   'warehouse',\n",
       "   'juggling',\n",
       "   'feather',\n",
       "   'bowling',\n",
       "   'ball',\n",
       "   'hisbase',\n",
       "   'histogrambased',\n",
       "   'main',\n",
       "   'memory',\n",
       "   'data',\n",
       "   'management',\n",
       "   'evaluation',\n",
       "   'adaptive',\n",
       "   'computing',\n",
       "   'concept',\n",
       "   'classical',\n",
       "   'system',\n",
       "   'enterprise',\n",
       "   'service',\n",
       "   'optimized',\n",
       "   'dynamic',\n",
       "   'allocation',\n",
       "   'management',\n",
       "   'system',\n",
       "   'enterprise',\n",
       "   'service',\n",
       "   'towards',\n",
       "   'contextaware',\n",
       "   'adaptable',\n",
       "   'service',\n",
       "   'serviceglobe',\n",
       "   'flexible',\n",
       "   'reliable',\n",
       "   'service',\n",
       "   'internet',\n",
       "   'streamglobe',\n",
       "   'adaptive',\n",
       "   'query',\n",
       "   'processing',\n",
       "   'optimization',\n",
       "   'streaming',\n",
       "   'environment']),\n",
       " (1,\n",
       "  ['specification',\n",
       "   'execution',\n",
       "   'transactional',\n",
       "   'workflow',\n",
       "   'using',\n",
       "   'polytransactions',\n",
       "   'manage',\n",
       "   'interdependent',\n",
       "   'data',\n",
       "   'algebraic',\n",
       "   'language',\n",
       "   'graphical',\n",
       "   'query',\n",
       "   'formulation',\n",
       "   'using',\n",
       "   'extended',\n",
       "   'entityrelationship',\n",
       "   'model',\n",
       "   'semantics',\n",
       "   'update',\n",
       "   'operation',\n",
       "   'extended',\n",
       "   'entityrelationship',\n",
       "   'model',\n",
       "   'query',\n",
       "   'transformation',\n",
       "   'multidatabase',\n",
       "   'environment',\n",
       "   'using',\n",
       "   'universal',\n",
       "   'symbolic',\n",
       "   'manipulation',\n",
       "   'system',\n",
       "   'workflow',\n",
       "   'service',\n",
       "   'composition',\n",
       "   'virtual',\n",
       "   'enterprise',\n",
       "   'transaction',\n",
       "   'transactional',\n",
       "   'workflow',\n",
       "   'technology',\n",
       "   'application',\n",
       "   'transactional',\n",
       "   'workflow',\n",
       "   'management',\n",
       "   'distributed',\n",
       "   'system',\n",
       "   'invited',\n",
       "   'paper',\n",
       "   'request',\n",
       "   'testbed',\n",
       "   'relational',\n",
       "   'database',\n",
       "   'management',\n",
       "   'system',\n",
       "   'instructional',\n",
       "   'research',\n",
       "   'purpose',\n",
       "   'towards',\n",
       "   'selfmanaging',\n",
       "   'large',\n",
       "   'scale',\n",
       "   'information',\n",
       "   'system',\n",
       "   'database',\n",
       "   'environment',\n",
       "   'workflow',\n",
       "   'specification',\n",
       "   'execution',\n",
       "   'multidatabase',\n",
       "   'transaction',\n",
       "   'impediment',\n",
       "   'opportunity',\n",
       "   'identification',\n",
       "   'missing',\n",
       "   'information',\n",
       "   'resource',\n",
       "   'query',\n",
       "   'difference',\n",
       "   'operator',\n",
       "   'coordination',\n",
       "   'workflow',\n",
       "   'group',\n",
       "   'activity',\n",
       "   'composition',\n",
       "   'management',\n",
       "   'virtual',\n",
       "   'enterprise',\n",
       "   'implementation',\n",
       "   'model',\n",
       "   'muldidatabase',\n",
       "   'query',\n",
       "   'providing',\n",
       "   'transactional',\n",
       "   'property',\n",
       "   'migrating',\n",
       "   'workflow',\n",
       "   'extending',\n",
       "   'multidatabase',\n",
       "   'manipulation',\n",
       "   'language',\n",
       "   'resolve',\n",
       "   'schema',\n",
       "   'data',\n",
       "   'conflict',\n",
       "   'request',\n",
       "   'distributed',\n",
       "   'database',\n",
       "   'system',\n",
       "   'local',\n",
       "   'area',\n",
       "   'network',\n",
       "   'decentralized',\n",
       "   'deadlockfree',\n",
       "   'concurrency',\n",
       "   'control',\n",
       "   'method',\n",
       "   'multidatabase',\n",
       "   'transaction',\n",
       "   'serializability',\n",
       "   'distributed',\n",
       "   'nested',\n",
       "   'transaction',\n",
       "   'query',\n",
       "   'transformation',\n",
       "   'heterogeneous',\n",
       "   'distributed',\n",
       "   'database',\n",
       "   'system',\n",
       "   'approach',\n",
       "   'schema',\n",
       "   'integration',\n",
       "   'query',\n",
       "   'formulation',\n",
       "   'federated',\n",
       "   'database',\n",
       "   'system',\n",
       "   'serializability',\n",
       "   'multidatabase',\n",
       "   'transaction',\n",
       "   'forced',\n",
       "   'local',\n",
       "   'conflict',\n",
       "   'implementation',\n",
       "   'multikey',\n",
       "   'extendible',\n",
       "   'hashing',\n",
       "   'access',\n",
       "   'method',\n",
       "   'relational',\n",
       "   'dbms',\n",
       "   'collaboration',\n",
       "   'management',\n",
       "   'infrastructure',\n",
       "   'execution',\n",
       "   'extended',\n",
       "   'multidatabase',\n",
       "   'distributed',\n",
       "   'operation',\n",
       "   'language',\n",
       "   'specifying',\n",
       "   'multisystem',\n",
       "   'application',\n",
       "   'distributed',\n",
       "   'processing',\n",
       "   'query',\n",
       "   'document',\n",
       "   'agent',\n",
       "   'based',\n",
       "   'information',\n",
       "   'retrieval',\n",
       "   'system',\n",
       "   'query',\n",
       "   'generation',\n",
       "   'instructional',\n",
       "   'database',\n",
       "   'management',\n",
       "   'system',\n",
       "   'infosleuth',\n",
       "   'semantic',\n",
       "   'integration',\n",
       "   'information',\n",
       "   'open',\n",
       "   'dynamic',\n",
       "   'environment',\n",
       "   'experience',\n",
       "   'paper',\n",
       "   'infosleuth',\n",
       "   'project',\n",
       "   'concurrency',\n",
       "   'control',\n",
       "   'recovery',\n",
       "   'multidatabase',\n",
       "   'work',\n",
       "   'flow',\n",
       "   'telecommunication',\n",
       "   'application',\n",
       "   'panel',\n",
       "   'multidatabase',\n",
       "   'system',\n",
       "   'primitive',\n",
       "   'maintenance',\n",
       "   'replicated',\n",
       "   'data',\n",
       "   'object',\n",
       "   'transaction',\n",
       "   'management',\n",
       "   'distributed',\n",
       "   'database',\n",
       "   'system',\n",
       "   'local',\n",
       "   'area',\n",
       "   'network',\n",
       "   'using',\n",
       "   'flexible',\n",
       "   'transaction',\n",
       "   'support',\n",
       "   'multisystem',\n",
       "   'telecommunication',\n",
       "   'application',\n",
       "   'specifying',\n",
       "   'enforcing',\n",
       "   'intertask',\n",
       "   'dependency',\n",
       "   'multidatabase',\n",
       "   'transaction',\n",
       "   'model',\n",
       "   'interbase',\n",
       "   'towards',\n",
       "   'cooperative',\n",
       "   'transaction',\n",
       "   'model',\n",
       "   'cooperative',\n",
       "   'activity',\n",
       "   'model',\n",
       "   'multidatabase',\n",
       "   'application',\n",
       "   'semantic',\n",
       "   'system',\n",
       "   'issue',\n",
       "   'automatic',\n",
       "   'generation',\n",
       "   'ontology',\n",
       "   'based',\n",
       "   'annotation',\n",
       "   'retrieval',\n",
       "   'system',\n",
       "   'management',\n",
       "   'interdependent',\n",
       "   'data',\n",
       "   'specifying',\n",
       "   'dependency',\n",
       "   'consistency',\n",
       "   'requirement'])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brdd2.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['overview',\n",
       " 'iris',\n",
       " 'dbms',\n",
       " 'overview',\n",
       " 'iris',\n",
       " 'dbms',\n",
       " 'physician',\n",
       " 'workstation',\n",
       " 'objectoriented',\n",
       " 'healthcare']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_stop_words = brdd2.flatMap(lambda r: r[1]).map(lambda r: (r,1)).reduceByKey(lambda a,b: a+b)\n",
    "\n",
    "doc_stop_words = doc_stop_words.filter(lambda a: a[1]>15000).map(lambda r: r[0]).collect()\n",
    "\n",
    "brdd3 = brdd2.map(lambda r: (r[0],[w for w in r[1] if not w in doc_stop_words]))    \n",
    "\n",
    "brdd3.take(1)[0][1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dummy=1, words=['overview', 'iris', 'dbms', 'overview', 'iris', 'dbms', 'physician', 'workstation', 'objectoriented', 'healthcare', 'powerful', 'widearea', 'clent', 'functional', 'integrating', 'structuredtext', 'objectoriented'])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B.2. Convert tokens into sparse vectors\n",
    "brdd4 = spark.createDataFrame(brdd3, [\"dummy\",\"words\"])\n",
    "brdd4.cache()\n",
    "brdd4.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|dummy|               words|            features|\n",
      "+-----+--------------------+--------------------+\n",
      "|    1|[overview, iris, ...|(158039,[66,92,11...|\n",
      "|    1|[physical, base, ...|(158039,[0,3,9,11...|\n",
      "|    1|[specification, e...|(158039,[6,7,13,2...|\n",
      "|    1|[specification, e...|(158039,[2,3,4,6,...|\n",
      "|    1|[spatial, firstcl...|(158039,[1,23,26,...|\n",
      "|    1|[version, objecto...|(158039,[3,26,45,...|\n",
      "|    1|[gemstone, persis...|(158039,[116,1239...|\n",
      "|    1|[storage, exodus,...|(158039,[3,9,11,1...|\n",
      "|    1|[storage, exodus,...|(158039,[49,66,99...|\n",
      "|    1|[manager, coopera...|(158039,[3,15,41,...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cvb = CountVectorizer(inputCol=\"words\", outputCol=\"features\", minDF=2)\n",
    "\n",
    "cv_modelb = cvb.fit(brdd4)\n",
    "\n",
    "brdd4_df_w_features = cv_modelb.transform(brdd4)\n",
    "brdd4_df_w_features.cache()\n",
    "brdd4_df_w_features.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseVector(158039, {66: 2.0, 92: 1.0, 111: 1.0, 457: 2.0, 931: 1.0, 991: 1.0, 1225: 2.0, 1382: 2.0, 1980: 1.0, 3158: 1.0, 4530: 1.0, 94917: 1.0, 132293: 1.0})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "#from pyspark.ml import linalg as ml_linalg\n",
    "def as_mllib_vector(v):\n",
    "    return Vectors.sparse(v.size, v.indices, v.values)\n",
    "\n",
    "bfeatures = brdd4_df_w_features.select(\"features\")\n",
    "bfeature_vec = bfeatures.rdd.map(lambda r: as_mllib_vector(r[0]))\n",
    "\n",
    "bfeature_vec.cache()\n",
    "bfeature_vec.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary from CountVectorizerModel is:\n",
      "['integrated', 'sequence', 'component', 'mechanism', 'visualization', 'linear', 'specification', 'flow', 'task', 'matching', 'hierarchical', 'comparison', 'platform', 'ontology', 'text', 'computation', 'improving', 'theory', 'traffic', 'device', 'domain', 'effect', 'vector', 'local', 'internet', 'experience', 'scalable', 'automated', 'modelling', 'game', 'heterogeneous', 'abstract', 'content', 'coding', 'face', 'project', 'synthesis', 'path', 'secure', 'active', 'identification', 'requirement', 'filter', 'spatial', 'monitoring', 'cluster', 'distribution', 'formal', 'reasoning', 'supporting', 'level', 'multiagent', 'methodology', 'error', 'business', 'concept', 'source', 'discovery', 'improved', 'building', 'solution', 'complexity', 'complex', 'context', 'group', 'evolutionary', 'objectoriented', 'allocation', 'signal', 'mapping', 'surface', 'temporal', 'behavior', 'state', 'reduction', 'social', 'shape', 'hardware', 'probabilistic', 'evolution', 'reconfigurable', 'flexible', 'field', 'description', 'statistical', 'construction', 'extended', 'measurement', 'global', 'cooperative', 'energy', 'result', 'integrating', 'delay', 'library', 'computational', 'reconstruction', 'impact', 'product', 'medical']\n"
     ]
    }
   ],
   "source": [
    "print (\"Vocabulary from CountVectorizerModel is:\")\n",
    "print(cv_modelb.vocabulary[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B.3. Use the LDA algorithm to find out 10 topics for each publication \n",
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "lda = LDA(k=10, maxIter=20)\n",
    "blda_model = lda.fit(brdd4_df_w_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+-----------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|topic|termIndices                                                |termWeights                                                                                                                                                                                                                     |\n",
      "+-----+-----------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0    |[4, 70, 19, 80, 170, 134, 75, 25, 35, 21]                  |[0.004227554472586488, 0.003389971777830954, 0.003139044219339341, 0.0030753620415430644, 0.002769820797966382, 0.0026908194990773624, 0.002629848231678775, 0.0026031824751343684, 0.002513721453970944, 0.00229732561037692]  |\n",
      "|1    |[27, 83, 96, 82, 34, 61, 76, 147, 272, 91]                 |[8.115137752385802E-4, 7.82622705383776E-4, 5.99169500188702E-4, 5.829320669505773E-4, 5.759523865375699E-4, 5.07859531195633E-4, 4.976695647395341E-4, 4.820224647907028E-4, 4.568969193238561E-4, 4.210569005985669E-4]       |\n",
      "|2    |[66, 44, 139, 6, 42, 0, 124, 45, 18, 5]                    |[0.002096480270249684, 9.185697283502052E-4, 7.614109032247973E-4, 4.874280810115121E-4, 4.722184073561751E-4, 4.655472447120279E-4, 4.4874596511315325E-4, 4.2495390633928286E-4, 3.9709256127179525E-4, 3.816006574715067E-4] |\n",
      "|3    |[1237, 3388, 4271, 4073, 3825, 4546, 4482, 5203, 5340, 127]|[0.0038725121171022656, 9.81716276151712E-4, 7.625813284531293E-4, 7.242656083273684E-4, 6.94425130534806E-4, 6.411169158224058E-4, 6.255394569175426E-4, 5.238765198320675E-4, 5.040918182842747E-4, 4.785007608762998E-4]     |\n",
      "|4    |[6, 14, 15, 5, 2, 31, 13, 17, 48, 1]                       |[0.002432121679928798, 0.0024256551122813223, 0.002306877732923981, 0.0022456894437107764, 0.0022269304982206225, 0.002212767724375857, 0.002208682297809963, 0.0021966526410620783, 0.002140993762196217, 0.002135411263561603]|\n",
      "|5    |[33, 147, 42, 93, 156, 107, 68, 18, 185, 53]               |[0.007160617967359505, 0.00543264361849373, 0.005023174894006111, 0.004650837132554475, 0.004512311723941743, 0.0044386062694015665, 0.00424657281928744, 0.004207529683425455, 0.003973181889193302, 0.0038488530104033108]    |\n",
      "|6    |[943, 994, 1094, 1363, 1810, 1950, 2156, 2147, 1527, 2324] |[0.004163861829278243, 0.003467988384018991, 0.0033379580434289803, 0.002421740840991055, 0.0018247076634372293, 0.0017494089230020839, 0.00170552490393988, 0.001356782809268505, 0.0012485234647952859, 0.0011989393096076936]|\n",
      "|7    |[273, 189, 264, 400, 310, 375, 933, 1020, 860, 547]        |[0.008271356207925068, 0.008192250522982555, 0.005775527574959162, 0.004635166927454712, 0.004513052386828275, 0.004507664038333801, 0.0029479950130969898, 0.0026900759345325127, 0.0026161846798142775, 0.0026100097125740375]|\n",
      "|8    |[312, 65, 846, 87, 2380, 2099, 70, 21, 2571, 2969]         |[0.0013846985078785827, 0.0013195930991632358, 0.0011987108037041143, 9.816931358255395E-4, 9.801649196514758E-4, 9.143573267363309E-4, 8.316331901287971E-4, 7.966406205153067E-4, 7.363421041393436E-4, 7.033159644998745E-4] |\n",
      "|9    |[109, 3000, 17, 53, 2774, 5740, 14, 154, 43, 318]          |[6.510315661354237E-4, 5.183490443028409E-4, 4.4105776638925416E-4, 4.21934411258227E-4, 3.9779161743878916E-4, 3.851547039317173E-4, 3.817006053594351E-4, 3.734089536869413E-4, 3.714539576281809E-4, 3.6351822273196944E-4]  |\n",
      "+-----+-----------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "['visualization' 'surface' 'device' 'reconfigurable' 'reality'\n",
      " 'navigation' 'social' 'experience' 'project' 'effect']\n",
      "['automated' 'description' 'reconstruction' 'field' 'face' 'complexity'\n",
      " 'shape' 'cmos' 'map' 'result']\n",
      "['objectoriented' 'monitoring' 'enterprise' 'specification' 'filter'\n",
      " 'integrated' 'speech' 'cluster' 'traffic' 'linear']\n",
      "['para' 'datos' 'modelos' 'sistemas' 'requisitos' 'desarrollo' 'sistema'\n",
      " 'modelo' 'objetos' 'stream']\n",
      "['specification' 'text' 'computation' 'linear' 'component' 'abstract'\n",
      " 'ontology' 'theory' 'reasoning' 'sequence']\n",
      "['coding' 'cmos' 'filter' 'delay' 'transmission' 'optical' 'signal'\n",
      " 'traffic' 'packet' 'error']\n",
      "['eines' 'eine' 'einer' 'durch' 'entwicklung' 'beispiel' 'einem' 'einsatz'\n",
      " 'analyse' 'modellierung']\n",
      "['student' 'education' 'science' 'course' 'teaching' 'elearning'\n",
      " 'curriculum' 'school' 'egovernment' 'educational']\n",
      "['brain' 'evolutionary' 'pour' 'measurement' 'pulmonary' 'left' 'surface'\n",
      " 'effect' 'knee' 'ventricle']\n",
      "['electronic' 'segmentierung' 'theory' 'error' 'automatische' 'bilddaten'\n",
      " 'text' 'composition' 'spatial' 'imaging']\n"
     ]
    }
   ],
   "source": [
    "# Describe topics\n",
    "btopics = blda_model.describeTopics(10)\n",
    "\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "\n",
    "btopics.show(truncate=False)\n",
    "\n",
    "# Shows the results\n",
    "#transformed = lda_model.transform(news_df_w_features)\n",
    "#transformed.columns\n",
    "import numpy as np\n",
    "btopic_i = btopics.select(\"termIndices\").rdd.map(lambda r: r[0]).collect()\n",
    "for i in btopic_i:\n",
    "    print(np.array(cv_modelb.vocabulary)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bll = blda_model.logLikelihood(brdd4_df_w_features)\n",
    "blp = blda_model.logPerplexity(brdd4_df_w_features)\n",
    "\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(bll))\n",
    "print(\"The upper bound on the perplexity: \" + str(blp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B4. Comment on results\n",
    "\n",
    "Using the same tokenizing process, I trained the model using the same parameters as part A. Visually, performance seems to have improved, because of the improvement in interpretability of topics. This could be due to the increase in the number of words in each document. The perplexity score function was run but it did not manage to give an output despite running for more than 3 hours."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
